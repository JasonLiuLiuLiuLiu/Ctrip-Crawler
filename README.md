# Ctrip-Crawler

Ctrip-Crawler 是一款面向携程航班信息数据采集的专业爬虫工具，基于 Selenium 与 SeleniumWire 构建高仿真浏览器自动化方案，解决直接调用 API 时面临的 IP 限制、JS 加密及验证码验证等问题。项目通过智能化错误处理、多账户登录、Cookie 缓存以及 IPV6 代理策略，确保数据采集的高效性与稳定性。

> **温馨提示**：JS 逆向版本正在研发中，后续将进一步提升性能与扩展性。

------

## 目录

- [项目概述](#项目概述)
- [技术架构](#技术架构)
- [主要特性](#主要特性)
- [安装与环境配置](#安装与环境配置)
- [使用说明](#使用说明)
- [配置选项详解](#配置选项详解)
- [数据输出与后续处理](#数据输出与后续处理)
- [文档和教程](#文档和教程)
- [待办事项](#待办事项)
- [贡献与反馈](#贡献与反馈)
- [许可证](#许可证)

------

## 项目概述

Ctrip-Crawler 专注于从携程官网实时提取航班数据，其核心在于通过自动化浏览器模拟真实用户操作，规避了 API 调用中的诸多限制（例如 IP 封禁、JS 加密与验证码验证）。借助 Selenium 及其扩展 SeleniumWire，工具不仅能够捕获网络请求，还能动态解析 gzip 压缩和 JSON 格式的数据，最终利用 pandas 构建结构化数据，生成便于后续分析的 CSV 文件。

------

## 技术架构

- **浏览器自动化模拟**
   利用 Selenium 模拟真实浏览器操作，通过隐身模式和高级选项（如无头模式、禁用 GPU 加速等）保证环境隔离和性能优化，同时借助 SeleniumWire 实现网络请求捕获与数据截取。
- **多线程与容错处理**
   内置细粒度的异常捕捉与重试机制，对页面加载超时、验证码触发、网络请求异常等情况进行智能判断和错误恢复，并支持多账户自动切换及 Cookie 缓存，有效降低登录失败风险。
- **IPV6 代理与验证码应对**
   针对携程对 IP 的严格限制，采用 IPV6 地址生成策略实现流量分散；同时内置验证码检测与人工干预提示机制，确保在验证码触发时快速响应。
- **数据解码与后处理**
   通过 python-magic 判断响应 MIME 类型，并根据 gzip 或 JSON 格式进行数据解码；利用 pandas 对航班数据与票价信息进行合并、去重和重命名，形成标准化的数据输出。

------

## 主要特性

- **高度定制化的 Selenium 模拟**
   完整模拟点击、输入、页面滚动、元素交互及验证码识别等操作，真实还原用户浏览体验。
- **灵活的错误重试与异常处理**
   针对页面加载失败、网络请求异常、验证码验证超时等问题，提供多重重试机制和详细日志输出，确保数据采集不中断。
- **IP 限制绕过策略**
   利用携程对 IPV6 的支持，通过大量 IPV6 地址生成及代理策略，突破传统 IP 限制，提高采集成功率。
- **自动化登录与 Cookie 缓存**
   支持多账户自动登录，自动检测并缓存 Cookie 信息，减少重复登录带来的开销，提升操作效率。
- **数据质量与完整性校验**
   严格检测返回数据的完整性、关键字段匹配和数据类型，确保采集数据准确无误，并支持对航班舒适度信息的深度解析。
- **详细日志与调试支持**
   内置详细日志输出和错误截图记录功能，为问题定位与系统调优提供有力支持。

------

## 安装与环境配置

1. **环境要求**

   - Python 3.6 及以上版本

2. **依赖安装**
    执行以下命令安装项目所需依赖：

   ```bash
   pip install -r requirements.txt
   ```

   依赖库主要包括：

   - `selenium` 与 `seleniumwire`
   - `pandas`
   - `python-magic`
   - 其他标准库模块（如 `gzip`、`json`、`datetime`、`threading` 等）

3. **浏览器驱动配置**
    根据所选浏览器（Chrome 或 Edge）下载相应的驱动程序，并在代码中配置正确的驱动路径，确保驱动版本与浏览器版本匹配。

------

## 使用说明

1. **参数配置**
    在主脚本中，可通过修改以下参数进行自定义配置：

   - **爬取城市与航线组合**：修改 `crawal_citys` 列表（例如：`["上海", "香港", "东京"]`），工具会自动生成出发与目的地的组合。
   - **爬取日期范围与间隔**：设置 `begin_date`、`end_date`、`start_interval` 和 `crawal_days`，自定义日期生成逻辑。
   - **操作间隔与超时时间**：通过 `crawal_interval`、`days_interval` 和 `max_wait_time` 控制页面交互间隔及等待时间。
   - **数据采集策略**：配置 `direct_flight`（是否仅采集直飞航班）、`comft_flight`（是否采集舒适度信息）以及是否删除冗余字段（`del_info`）。
   - **登录配置**：设置 `accounts`、`passwords` 与 `COOKIES_FILE` 路径，实现自动登录及 Cookie 缓存。

2. **启动爬虫**
    在终端中执行以下命令启动爬虫：

   ```bash
   python your_script_name.py
   ```

   程序将依次执行以下流程：

   - 初始化浏览器及网络请求捕获机制；
   - 自动登录携程（包含验证码识别及人工干预）；
   - 按照设定的城市与日期循环采集航班数据、票价信息和舒适度数据；
   - 对数据进行解码、校验与整合，最终输出 CSV 文件，数据存储路径格式为 `./<航班日期>/<当前日期>/<出发城市>-<目的城市>.csv`。

3. **数据输出**
    采集到的数据经过结构化处理后，将以 CSV 格式存储，便于后续数据分析、统计与可视化处理。

------

## 配置选项详解

- **浏览器选项与驱动初始化**
   通过 `init_driver()` 方法配置隐身模式、无头模式、禁用自动化提示等参数，确保模拟环境的隐蔽性和高效性。
- **错误处理机制**
   全局变量 `max_retry_time` 定义最大重试次数，在页面加载、元素查找、数据解析过程中出现异常时，程序会自动刷新页面或切换账户重试。
- **验证码与登录策略**
   内置验证码检测机制，通过监控 DOM 中特定元素（如 `verification-code`、`alert-title`）判断是否需要人工干预；支持通过 Cookie 本地缓存实现快速登录重连。
- **数据解码与压缩处理**
   利用 `python-magic` 判断响应数据格式，自动处理 gzip 压缩及 JSON 数据解析，确保数据的准确还原。

------

## 数据输出与后续处理

- **数据合并与重命名**
   通过 pandas 对航班信息、票价数据及舒适度数据进行合并，并依据预设映射关系重命名 DataFrame 列，形成标准化数据表。
- **数据质量校验**
   对返回数据中的城市、日期、航班号等关键字段进行严格校验，确保数据的准确性与完整性；对于异常情况（例如无直飞航班）提供日志提示与重采样机制。
- **存储策略**
   数据自动存储至本地目录，目录结构依据采集日期和当天日期自动归类管理，便于后续批量处理和分析。

------

## 文档和教程

详细的使用指南和开发文档可在以下博客中查看：

- [基于selenium的携程机票爬取程序](https://blog.suysker.xyz/archives/35)
- [基于selenium的携程机票爬取程序V2](https://blog.suysker.xyz/archives/139)
- [基于request的携程机票爬取程序](https://blog.suysker.xyz/archives/37)
- [基于request的航班历史票价爬取](https://blog.suysker.xyz/archives/36)

------

## 待办事项

- **JS 逆向版本**
   正在研发基于 JS 逆向的新版本，旨在进一步突破携程数据接口限制，提升数据采集效率与稳定性。
- **多线程分片采集**
   计划在 V4.0 中引入多线程分片运行机制，实现大规模并发数据采集，缩短整体采集时长。

------

## 贡献与反馈

我们欢迎各位开发者参与项目优化与功能扩展。若在使用过程中遇到问题、发现 bug 或有改进建议，请通过提交 Issue 或 Pull Request 与我们联系。感谢每一位贡献者的支持与热情参与！

------

## 许可证

本项目采用 [MIT License](LICENSE) 开源许可证。详见 LICENSE 文件。
